{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdftotext\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load text from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "\n",
    "# Load text from documents\n",
    "def loadTextFromFile(directory, filenames, docs):\n",
    "    trainingDirectory = CURRENT_PATH + \"/\" + directory\n",
    "    for filename in os.listdir(trainingDirectory):\n",
    "        filenames.append(int(filename[:-4]))  # Removes the .txt from the filename\n",
    "        with open(trainingDirectory + \"/\" + filename, \"r\") as file:\n",
    "            text = file.read()\n",
    "        docs.append(text)\n",
    "\n",
    "\n",
    "diversityInclusion = \"diversityInclusion\"\n",
    "diversityInclusionFilenames = []\n",
    "diversityInclusionDocs = []\n",
    "diversityInclusionTestFilenames = []\n",
    "diversityInclusionTestDocs = []\n",
    "loadTextFromFile(\n",
    "    diversityInclusion + \"/\" + \"training\",\n",
    "    diversityInclusionFilenames,\n",
    "    diversityInclusionDocs,\n",
    ")\n",
    "loadTextFromFile(\n",
    "    diversityInclusion + \"/\" + \"test\",\n",
    "    diversityInclusionTestFilenames,\n",
    "    diversityInclusionTestDocs,\n",
    ")\n",
    "\n",
    "\n",
    "encourageGenders = \"encourageGenders\"\n",
    "encourageGendersFilenames = []\n",
    "encourageGendersDocs = []\n",
    "encourageGendersTestFilenames = []\n",
    "encourageGendersTestDocs = []\n",
    "loadTextFromFile(\n",
    "    encourageGenders + \"/\" + \"training\",\n",
    "    encourageGendersFilenames,\n",
    "    encourageGendersDocs,\n",
    ")\n",
    "loadTextFromFile(\n",
    "    encourageGenders + \"/\" + \"test\",\n",
    "    encourageGendersTestFilenames,\n",
    "    encourageGendersTestDocs,\n",
    ")\n",
    "\n",
    "mentionOrgFeatures = \"mentionOrgFeatures\"\n",
    "mentionOrgFeaturesFilenames = []\n",
    "mentionOrgFeaturesDocs = []\n",
    "mentionOrgFeaturesTestFilenames = []\n",
    "mentionOrgFeaturesTestDocs = []\n",
    "loadTextFromFile(\n",
    "    mentionOrgFeatures + \"/\" + \"training\",\n",
    "    mentionOrgFeaturesFilenames,\n",
    "    mentionOrgFeaturesDocs,\n",
    ")\n",
    "loadTextFromFile(\n",
    "    mentionOrgFeatures + \"/\" + \"test\",\n",
    "    mentionOrgFeaturesTestFilenames,\n",
    "    mentionOrgFeaturesTestDocs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a table with two columns: filename ('id'), and the text from the file (the job ad)\n",
    "\n",
    "diversityInclusionData = pd.DataFrame()\n",
    "diversityInclusionData[\"id\"] = diversityInclusionFilenames\n",
    "diversityInclusionData[\"text\"] = diversityInclusionDocs\n",
    "diversityInclusionTestData = pd.DataFrame()\n",
    "diversityInclusionTestData[\"id\"] = diversityInclusionTestFilenames\n",
    "diversityInclusionTestData[\"text\"] = diversityInclusionTestDocs\n",
    "\n",
    "encourageGendersData = pd.DataFrame()\n",
    "encourageGendersData[\"id\"] = encourageGendersFilenames\n",
    "encourageGendersData[\"text\"] = encourageGendersDocs\n",
    "encourageGendersTestData = pd.DataFrame()\n",
    "encourageGendersTestData[\"id\"] = encourageGendersTestFilenames\n",
    "encourageGendersTestData[\"text\"] = encourageGendersTestDocs\n",
    "\n",
    "mentionOrgFeaturesData = pd.DataFrame()\n",
    "mentionOrgFeaturesData[\"id\"] = mentionOrgFeaturesFilenames\n",
    "mentionOrgFeaturesData[\"text\"] = mentionOrgFeaturesDocs\n",
    "mentionOrgFeaturesTestData = pd.DataFrame()\n",
    "mentionOrgFeaturesTestData[\"id\"] = mentionOrgFeaturesTestFilenames\n",
    "mentionOrgFeaturesTestData[\"text\"] = mentionOrgFeaturesTestDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove punctutation\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    # Convert to lower\n",
    "    text = text.lower()\n",
    "    # Remove whitespaces\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "diversityInclusionData[\"text\"] = diversityInclusionData[\"text\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")\n",
    "diversityInclusionTestData[\"text\"] = diversityInclusionTestData[\"text\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")\n",
    "\n",
    "encourageGendersTestData[\"text\"] = encourageGendersData[\"text\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")\n",
    "encourageGendersTestData[\"text\"] = encourageGendersTestData[\"text\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")\n",
    "\n",
    "mentionOrgFeaturesData[\"text\"] = mentionOrgFeaturesData[\"text\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")\n",
    "mentionOrgFeaturesTestData[\"text\"] = mentionOrgFeaturesTestData[\"text\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "# A function to remove stopwords and short length words (< 2)\n",
    "def remove_stopwords(text):\n",
    "    new = []\n",
    "    for word in text.split():\n",
    "        if word not in stop and len(word) > 1:\n",
    "            new.append(word)\n",
    "\n",
    "    return \" \".join(new)\n",
    "\n",
    "\n",
    "diversityInclusionData[\"text\"] = diversityInclusionData[\"text\"].apply(\n",
    "    lambda x: remove_stopwords(x)\n",
    ")\n",
    "diversityInclusionTestData[\"text\"] = diversityInclusionTestData[\"text\"].apply(\n",
    "    lambda x: remove_stopwords(x)\n",
    ")\n",
    "\n",
    "encourageGendersData[\"text\"] = encourageGendersData[\"text\"].apply(\n",
    "    lambda x: remove_stopwords(x)\n",
    ")\n",
    "encourageGendersTestData[\"text\"] = encourageGendersTestData[\"text\"].apply(\n",
    "    lambda x: remove_stopwords(x)\n",
    ")\n",
    "\n",
    "mentionOrgFeaturesData[\"text\"] = mentionOrgFeaturesData[\"text\"].apply(\n",
    "    lambda x: remove_stopwords(x)\n",
    ")\n",
    "mentionOrgFeaturesTestData[\"text\"] = mentionOrgFeaturesTestData[\"text\"].apply(\n",
    "    lambda x: remove_stopwords(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading pre-labeled target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversityInclusionLabels = pd.read_csv(\n",
    "    CURRENT_PATH + \"/labels/diversityInclusion.csv\"\n",
    ")\n",
    "diversityInclusionData = pd.merge(diversityInclusionData, diversityInclusionLabels)\n",
    "diversityInclusionTestLabels = pd.read_csv(\n",
    "    CURRENT_PATH + \"/labels/diversityInclusionTest.csv\"\n",
    ")\n",
    "diversityInclusionTestData = pd.merge(\n",
    "    diversityInclusionTestData, diversityInclusionTestLabels\n",
    ")\n",
    "\n",
    "\n",
    "encourageGendersLabels = pd.read_csv(CURRENT_PATH + \"/labels/encourageGenders.csv\")\n",
    "encourageGendersData = pd.merge(encourageGendersData, encourageGendersLabels)\n",
    "encourageGendersTestLabels = pd.read_csv(\n",
    "    CURRENT_PATH + \"/labels/encourageGendersTest.csv\"\n",
    ")\n",
    "encourageGendersTestData = pd.merge(\n",
    "    encourageGendersTestData, encourageGendersTestLabels\n",
    ")\n",
    "\n",
    "\n",
    "mentionOrgFeaturesLabels = pd.read_csv(\n",
    "    CURRENT_PATH + \"/labels/mentionOrgFeatures.csv\"\n",
    ")\n",
    "mentionOrgFeaturesData = pd.merge(mentionOrgFeaturesData, mentionOrgFeaturesLabels)\n",
    "mentionOrgFeaturesTestLabels = pd.read_csv(\n",
    "    CURRENT_PATH + \"/labels/mentionOrgFeaturesTest.csv\"\n",
    ")\n",
    "mentionOrgFeaturesTestData = pd.merge(\n",
    "    mentionOrgFeaturesTestData, mentionOrgFeaturesTestLabels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using word2vec for manually training embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gensim.models.Word2Vec(\n",
    "#         window = 10,\n",
    "#         min_count = 2,\n",
    "#         workers = 4\n",
    "# )\n",
    "\n",
    "# model.build_vocab(train['tokens'], progress_per=1000)\n",
    "\n",
    "# model.epochs\n",
    "\n",
    "# model.corpus_count\n",
    "\n",
    "# model.train(train['text'], total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# model.save(\"./word-2-vec.model\")\n",
    "\n",
    "# model.wv.most_similar(\"male\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pre-trained Glove word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# need to download the model from https://nlp.stanford.edu/projects/glove/\n",
    "# then add to directory\n",
    "glove_path = 'glove.twitter.27B.100d.txt'\n",
    "word2vec_output_file = 'MY_MODEL'+'.word2vec'\n",
    "\n",
    "glove2word2vec(glove_path, word2vec_output_file)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "GloVe model\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# # Lexvec model\n",
    "# model = KeyedVectors.load_word2vec_format('lexvec.commoncrawl.ngramsubwords.300d.W.pos.vectors', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King:  [-0.099438 -0.03811  -0.02814  -0.086827 -0.058872 -0.074074 -0.089723\n",
      "  0.007647 -0.079409 -0.077722  0.012145 -0.087492  0.125281  0.077101\n",
      " -0.017215  0.011123  0.011952 -0.002687 -0.119687  0.039859  0.037061\n",
      " -0.070333  0.015584 -0.232619 -0.076024 -0.092917 -0.015832  0.024597\n",
      "  0.022748 -0.081143 -0.002227  0.061346  0.185452  0.161941 -0.021561\n",
      "  0.006761  0.012353 -0.044067  0.057281 -0.12141  -0.114887  0.096228\n",
      "  0.107898 -0.173222  0.014622  0.023282  0.026272 -0.203771  0.113475\n",
      "  0.020428  0.05133   0.032807  0.042183 -0.061823  0.072173  0.065524\n",
      " -0.212801  0.071362 -0.080849 -0.019219 -0.018223 -0.255929  0.106209\n",
      " -0.002017  0.083529  0.109361 -0.121694  0.097796  0.112664  0.069995\n",
      "  0.093611 -0.048229  0.094784 -0.035936 -0.063447 -0.056852  0.080355\n",
      " -0.013907 -0.102584  0.033997 -0.072398 -0.046312  0.126431 -0.010575\n",
      " -0.144504  0.159152 -0.024255 -0.002653 -0.074009  0.009565  0.117276\n",
      " -0.007985  0.108225  0.141307  0.12105   0.002244 -0.109612  0.04216\n",
      " -0.003662  0.005441  0.033684 -0.051304 -0.024535 -0.043478 -0.107928\n",
      " -0.006781  0.067716  0.096214  0.088546 -0.00902  -0.085613 -0.189893\n",
      " -0.077919 -0.072262  0.048512 -0.074116 -0.031344  0.060342  0.22336\n",
      " -0.015441  0.210945  0.210324 -0.066394 -0.113293 -0.004934  0.012272\n",
      " -0.158739  0.023449 -0.070985  0.014054 -0.053843  0.094955  0.128091\n",
      " -0.161265  0.09974   0.028061  0.023285 -0.034525 -0.116481  0.18428\n",
      "  0.088241  0.05717   0.003599 -0.036244 -0.16789   0.129092  0.202253\n",
      "  0.050592 -0.118081 -0.024985 -0.007451 -0.020191 -0.006988 -0.033448\n",
      " -0.018563 -0.166033 -0.086745  0.151754  0.085839  0.073976  0.020392\n",
      "  0.121512 -0.13802  -0.069149 -0.227425 -0.07404  -0.078875 -0.085902\n",
      " -0.007233  0.149313  0.002322  0.099813  0.072284  0.123769  0.026011\n",
      "  0.00363   0.03411  -0.034771 -0.008135  0.075067 -0.065548  0.138004\n",
      "  0.096933  0.08235  -0.05773  -0.091836  0.024751 -0.079274 -0.033573\n",
      "  0.028516  0.069782 -0.08894  -0.021416 -0.031882  0.055589  0.128292\n",
      "  0.012657  0.16202  -0.005074 -0.16005  -0.035528  0.08843  -0.034235\n",
      "  0.033733 -0.02986  -0.046487  0.132608 -0.02022  -0.098516  0.212831\n",
      " -0.010373 -0.032101 -0.102831  0.073216 -0.046638  0.0324    0.008005\n",
      " -0.040234  0.184772  0.044332 -0.036239  0.056628  0.029386 -0.051182\n",
      " -0.107216 -0.030754 -0.067714 -0.020499  0.099033  0.136262  0.014374\n",
      " -0.099437  0.241561  0.188455  0.102933 -0.110954  0.022042  0.02328\n",
      "  0.02836   0.0437   -0.128002 -0.167871 -0.031789  0.0954   -0.005811\n",
      "  0.195208 -0.025032  0.106821  0.007605 -0.002155  0.122571  0.080701\n",
      " -0.074807 -0.140991 -0.097639  0.114417  0.163608 -0.070336 -0.015139\n",
      "  0.037212  0.142003 -0.110911  0.05894  -0.159409  0.070283 -0.095244\n",
      " -0.092594  0.005698  0.168796  0.058782  0.07496   0.089776  0.031367\n",
      "  0.217203 -0.10602  -0.01807  -0.012748  0.081134  0.06839   0.048653\n",
      " -0.115832  0.01078   0.00812  -0.04897  -0.06604  -0.018231 -0.046716\n",
      " -0.052852  0.108196 -0.063047 -0.091859 -0.138051 -0.177897 -0.182835\n",
      "  0.018694  0.101715  0.04978   0.082395 -0.103872  0.044244]\n",
      "Most similar word to King + Woman:  [('queen', 0.6833096146583557)]\n"
     ]
    }
   ],
   "source": [
    "#Show a word embedding\n",
    "print('King: ',model.get_vector('king'))\n",
    "\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "\n",
    "print('Most similar word to King + Woman: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('richness', 0.6089744567871094),\n",
       " ('Diversity', 0.5902432799339294),\n",
       " ('diverse', 0.5788357853889465),\n",
       " ('inclusiveness', 0.5460476279258728),\n",
       " ('uniqueness', 0.5407953262329102),\n",
       " ('pluralism', 0.5313884019851685),\n",
       " (\"diversity's\", 0.4992821514606476),\n",
       " ('diversities', 0.49747776985168457),\n",
       " (\"'diversity\", 0.4915635585784912),\n",
       " ('heritage', 0.48739439249038696)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find similar words to diversity\n",
    "model.most_similar('diversity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a class for vectorizing the sentences\n",
    "\n",
    "Source: https://edumunozsala.github.io/BlogEms/jupyter/nlp/classification/embeddings/python/2020/08/15/Intro_NLP_WordEmbeddings_Classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecVectorizer:\n",
    "  def __init__(self, model):\n",
    "    print(\"Loading in word vectors...\")\n",
    "    self.word_vectors = model\n",
    "    print(\"Finished loading in word vectors\")\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    # determine the dimensionality of vectors\n",
    "#     v = self.word_vectors.get_vector('king')\n",
    "#     self.D = v.shape[0]\n",
    "    self.D = model.vector_size\n",
    "\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.split()\n",
    "      vecs = []\n",
    "      m = 0\n",
    "      for word in tokens:\n",
    "        try:\n",
    "          # throws KeyError if word not found\n",
    "          vec = self.word_vectors.get_vector(word)\n",
    "          vecs.append(vec)\n",
    "          m += 1\n",
    "        except KeyError:\n",
    "          pass\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n"
     ]
    }
   ],
   "source": [
    "# Set a word vectorizer\n",
    "vectorizer = Word2VecVectorizer(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding each document and splitting into train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of samples with no words found: 0 / 7\n",
      "Numer of samples with no words found: 0 / 3\n",
      "Numer of samples with no words found: 0 / 5\n",
      "Numer of samples with no words found: 0 / 4\n",
      "Numer of samples with no words found: 0 / 8\n",
      "Numer of samples with no words found: 0 / 4\n",
      "[[array([[-0.00804881,  0.062328  , -0.0291645 , ..., -0.03117794,\n",
      "        -0.00888256,  0.06725182],\n",
      "       [-0.00181986,  0.05755581, -0.01650376, ..., -0.039441  ,\n",
      "         0.00648553,  0.03903401],\n",
      "       [-0.00280441,  0.05537559, -0.01449772, ..., -0.03154269,\n",
      "        -0.01114962,  0.04632628],\n",
      "       ...,\n",
      "       [ 0.016755  ,  0.04926629, -0.04735929, ..., -0.03480594,\n",
      "        -0.04079629,  0.05039847],\n",
      "       [-0.01481105,  0.03521071, -0.02987215, ..., -0.02515395,\n",
      "         0.00897514,  0.05121523],\n",
      "       [-0.00270411,  0.050753  , -0.01389973, ..., -0.02832008,\n",
      "         0.00645187,  0.01817235]]), array([1, 0, 1, 1, 1, 1, 1])], [array([[ 0.01952   ,  0.0242138 , -0.030083  , ..., -0.0551442 ,\n",
      "        -0.0313702 ,  0.04281221],\n",
      "       [-0.00979958,  0.04543   , -0.02935867, ..., -0.03090175,\n",
      "        -0.00638325,  0.03268158],\n",
      "       [-0.00590109,  0.05285313, -0.02409611, ..., -0.03392447,\n",
      "         0.01767478,  0.01981309],\n",
      "       [ 0.00710258,  0.03888149,  0.00239897, ..., -0.03529732,\n",
      "         0.00370391, -0.01042677],\n",
      "       [ 0.02275917,  0.04400139, -0.01000872, ..., -0.02609294,\n",
      "        -0.01801883,  0.00194856]]), array([1, 1, 0, 1, 1])], [array([[ 7.29751727e-03,  3.47783491e-02, -6.23869011e-03, ...,\n",
      "        -6.39157221e-02, -2.60195527e-02,  1.85706560e-02],\n",
      "       [ 3.24909319e-03,  7.68172890e-02, -2.27582618e-03, ...,\n",
      "        -2.92986427e-02, -6.51319930e-03,  3.92968133e-02],\n",
      "       [-7.40527612e-05,  2.89593153e-02, -7.86363333e-03, ...,\n",
      "        -6.20719939e-02,  1.17483689e-02,  3.90095264e-02],\n",
      "       ...,\n",
      "       [ 1.19745433e-02,  6.33801669e-02,  5.49399992e-03, ...,\n",
      "        -3.59167941e-02,  1.05949985e-02,  5.27834184e-02],\n",
      "       [ 1.25174578e-02,  2.74593327e-02, -1.14512444e-02, ...,\n",
      "        -4.17260751e-02, -1.43548772e-02,  2.87809670e-02],\n",
      "       [-1.63773817e-04,  5.12303822e-02, -1.19562633e-02, ...,\n",
      "        -4.56416607e-02,  5.74908590e-05,  3.97915840e-02]]), array([1, 1, 1, 0, 1, 1, 1, 1])]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "diversityInclusionText = vectorizer.fit_transform(diversityInclusionData[\"text\"])\n",
    "diversityInclusionLabels = np.array(diversityInclusionData[diversityInclusion])\n",
    "diversityInclusionTextFeatures = diversityInclusionText\n",
    "\n",
    "\n",
    "diversityInclusionTestText = vectorizer.fit_transform(diversityInclusionTestData[\"text\"])\n",
    "diversityInclusionTestLabels = np.array(diversityInclusionTestData[diversityInclusion])\n",
    "diversityInclusionTestTextFeatures = diversityInclusionTestText\n",
    "\n",
    "\n",
    "encourageGendersText = vectorizer.fit_transform(encourageGendersData[\"text\"])\n",
    "encourageGendersLabels = np.array(encourageGendersData[encourageGenders])\n",
    "encourageGendersTextFeatures = encourageGendersText #do we need to make it into an array from numpy\n",
    "\n",
    "encourageGendersTestText = vectorizer.fit_transform(\n",
    "    encourageGendersTestData[\"text\"]\n",
    ")\n",
    "encourageGendersTestLabels = np.array(encourageGendersTestData[encourageGenders])\n",
    "encourageGendersTestTextFeatures = encourageGendersTestText\n",
    "\n",
    "\n",
    "mentionOrgFeaturesText = vectorizer.fit_transform(\n",
    "    mentionOrgFeaturesData[\"text\"]\n",
    ")\n",
    "mentionOrgFeaturesLabels = np.array(mentionOrgFeaturesData[mentionOrgFeatures])\n",
    "mentionOrgFeaturesTextFeatures = mentionOrgFeaturesText\n",
    "\n",
    "mentionOrgFeaturesTestText = vectorizer.fit_transform(\n",
    "    mentionOrgFeaturesTestData[\"text\"]\n",
    ")\n",
    "mentionOrgFeaturesTestLabels = np.array(mentionOrgFeaturesTestData[mentionOrgFeatures])\n",
    "mentionOrgFeaturesTestTextFeatures = mentionOrgFeaturesTestText\n",
    "\n",
    "\n",
    "\n",
    "trainingData = [\n",
    "    [diversityInclusionTextFeatures, diversityInclusionLabels],\n",
    "    [encourageGendersTextFeatures, encourageGendersLabels],\n",
    "    [mentionOrgFeaturesTextFeatures, mentionOrgFeaturesLabels],\n",
    "]\n",
    "print(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and evluating a machine learning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Classification report for diversityInclusion \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.50000   0.66667         2\n",
      "           1    0.50000   1.00000   0.66667         1\n",
      "\n",
      "    accuracy                        0.66667         3\n",
      "   macro avg    0.75000   0.75000   0.66667         3\n",
      "weighted avg    0.83333   0.66667   0.66667         3\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\t Classification report for encourageGenders \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.00000   0.00000   0.00000         3\n",
      "           1    0.25000   1.00000   0.40000         1\n",
      "\n",
      "    accuracy                        0.25000         4\n",
      "   macro avg    0.12500   0.50000   0.20000         4\n",
      "weighted avg    0.06250   0.25000   0.10000         4\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "\t Classification report for mentionOrgFeatures \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000         1\n",
      "           1    1.00000   1.00000   1.00000         3\n",
      "\n",
      "    accuracy                        1.00000         4\n",
      "   macro avg    1.00000   1.00000   1.00000         4\n",
      "weighted avg    1.00000   1.00000   1.00000         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = []\n",
    "\n",
    "for i in range(len(trainingData)):\n",
    "    rf = RandomForestClassifier(n_estimators=200)\n",
    "    models.append(rf.fit(trainingData[i][0], trainingData[i][1])) #words[i][0], labels[i][1]\n",
    "\n",
    "predictions = []\n",
    "predictions.append(models[0].predict(diversityInclusionTestTextFeatures))\n",
    "predictions.append(\n",
    "    models[1].predict(encourageGendersTestTextFeatures)\n",
    ")  # Encourage both genders\n",
    "predictions.append(\n",
    "    models[2].predict(mentionOrgFeaturesTestTextFeatures)\n",
    ")  # Mention of work features\n",
    "\n",
    "# Evaluating precisions\n",
    "print(\"\\t Classification report for\", diversityInclusion, \"\\n\")\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        diversityInclusionTestLabels, predictions[0], digits=5\n",
    "    )\n",
    ")\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\t Classification report for\", encourageGenders, \"\\n\")\n",
    "print(\n",
    "    metrics.classification_report(encourageGendersTestLabels, predictions[1], digits=5)\n",
    ")\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\t Classification report for\", mentionOrgFeatures, \"\\n\")\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        mentionOrgFeaturesTestLabels, predictions[2], digits=5\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
